{
    "collab_server" : "",
    "contents" : "Session 4\n========================================================\nauthor: Mandy / Thomas\ndate: `r format(Sys.time(), '%d %B, %Y')`\nautosize: true\ncss: ../css/talk.css\ntransition: rotate\nnavigation: section\nfont-family: times, serif\n\nRecap\n========================================================\nincremental: true\n## You should know:\n- **statistics** is all about **simplifying**\n- we try to **summarize** and **describe** data through **parameters** of:\n    - *LOCATION* \n        - e.g. *mean, median, mode* \n    - *SCALE*\n        - e.g. *variance, standard deviation*\n    - *SPREAD*\n        - e.g. *minimum / maximum / range / quantile / IQR* \n- the meaning of these parameters\n- necessary R commands  \n\nRecap\n========================================================\nincremental: true\n## We have seen how\n- parameters of   \n    - location of two groups (means)\n    - spread  (standard deviation)\n    - uncertainty (sample size)\nincremental: true\n- to measure a difference of the location in a standardized manner \n- this measure is compared to a t-distribution relating to a so called **Null-Hypotheses** which one \"hopefully\" will be rejected to show an effect could exist \n\nRecap\n========================================================\nincremental: true\n## We have seen how\n- this comparision is transformed to a propabiltiy **(p-value)** to get this result by random \n- comparing this propability with a defined maximum propability for a random result (normally 5%) gives the opportunity to decide whether the effect could exist or not\n- important is also the effect size itself  \n(e.g. is an effect of $\\mu_2 - \\mu_1 = 101 - 100 = 1$ relevant?)\n\nTest Statistic\n============================================\nincremental: true\n- some property of two groups (Men and Women) are measured.  \n- to compare their means, we apply the so called **T-Test**\n- to do this we compute the so called **T-Statistic**:  \n\n$$t=\\frac{\\bar{X}_{m}-\\bar{X}_{w}}{s_{overall}\\sqrt{\\frac{1}{n_{m}}+\\frac{1}{n_{w}}}}$$\n\nDecisions can be right or wrong\n========================================================\n\n|                       | $H_0$ is true    | $H_0$ is false   |\n|-----------------------|------------------|------------------|\n| $H_0$ is not rejected | Correct decision | Type II error    |\n| $H_0$ is rejected     | Type I error     | Correct decision |\n\n\nAlternative of alternatives\n========================================================\nincremental: true\nalternative    | options  \n-------------- | ----------------\none sided test | less \n               | greater\ntwo sided test | equal   \n---------------- | ----------------\none sample test  |  \ntwo sample test  | equal variances\n                 | not necessary equal variances  \n-------------- | ----------------\nunpaired       | \npaired         |  \n\nAlternative of alternatives\n========================================================\n* two sided - equal\n\n```{r,echo=FALSE,fig.height=8,fig.width = 12,fig.align='center'}\n    curve(dt(x,df=1000),from = -4,to = 4)\n    text(-4,0.35,\"alternative: two sided\",pos=4)\n    abline(h=0)\n    x <- seq(-4,qt(0.025,df=1000),by=0.01)\n    y <- dnorm(x)\n    x <- c(x,qt(0.025,df=1000))\n    y <- c(y,dt(-4,df=1000))\n    polygon(x,y,col=\"red\")\n    \n    x <- seq(qt(0.975,df=1000),4,by=0.01)\n    y <- dt(x,df=1000)\n    x <- c(x,qt(0.975,df=1000))\n    y <- c(y,dt(4,df=1000))\n    polygon(x,y,col=\"red\")\n    \n    text(-2.75,0.02,expression(paste(\"reject \",H[0])),pos=4)\n    text(1.9,0.02,expression(paste(\"reject \",H[0])),pos=4)\n```\n\nAlternative of alternatives\n===\n* one sided - less\n\n```{r, echo=FALSE,fig.height=8,fig.width=12,fig.align='center'}\ncurve(dt(x,df=1000),-4,4)\nabline(h=0)\nx <- seq(-4,qt(0.05,df=1000),by=0.01)\ny <- dt(x,df=1000)\nx <- c(x,qt(0.05,df=1000))\ny <- c(y,dt(-4,df=1000))\npolygon(x,y,col=\"red\")\n\ntext(-4,0.35,\"alternative: less\",pos=4)\ntext(-2.45,0.02,expression(paste(\"reject \",H[0])),pos=4)\n\n```\n\nAlternative of alternatives\n===\n* one sided - greater\n\n```{r, echo=FALSE,fig.height=8,fig.width=12,fig.align='center'}\ncurve(dt(x,df=1000),-4,4)\nabline(h=0)\n\nx <- seq(qt(0.95,df=1000),4,by=0.01)\ny <- dt(x,df=1000)\nx <- c(x,qt(0.95,df=1000))\ny <- c(y,dt(4,df=1000))\npolygon(x,y,col=\"red\")\n\ntext(-4,0.35,\"alternative: greater\",pos=4)\ntext(1.6,0.02,expression(paste(\"reject \",H[0])),pos=4)\n```\n\nT-Tests in R\n========================================================\nincremental: true\n**There are many options more but only one command in R:**\n\n```t.test( )```\n\n\n\nT-Tests in R\n===\nclass: small-code\nincremental:true\n**One Sample T-Test**\n```{r}\nset.seed( 1 )\nx <- rnorm( 12 ) ## create random numbers\nt.test( x, mu = 0 ) ## population mean 0\n```  \n\nT-Tests in R\n===\nclass: small-code\nincremental:true\n**One Sample T-Test**\n```{r}\nt.test( x, mu = 1 ) ## population mean 1\n```\n\nT-Tests in R\n===\nclass: small-code\nincremental:true\n**Two Samples T-Test**\n- we have given a two numeric vectors\n- we do not assume equal variances for the underlying distributions\n\n```{r}\nset.seed( 1 )\nx <- rnorm( 12 )\ny <- rnorm( 12 )\nhead( data.frame( x, y ) )\n```\n\nT-Tests in R\n===\nclass: small-code\nincremental:true\n**Two Samples T-Test**\n```{r}\nt.test( x, y )\n```\n\nT-Tests in R\n===\nclass: small-code\nincremental:true\n**Two Samples T-Test**\n- we have one numeric vector and one vector containing the group information\n- we do not assume equal variances for the underlying distribution\n```{r}\n## create random group vector\ng <- sample( c( \"A\", \"B\" ), 12, replace = T )\nhead( data.frame( x, g ) )\n```\n\nT-Tests in R\n===\nclass: small-code\nincremental:true\n**Two Samples T-Test**\n```{r}\nt.test( x ~ g )\n```\n\nT-Tests in R\n===\nclass: small-code\nincremental:true\n**Two Samples T-Test**\n- equal variances now\n```{r}\nt.test( x ~ g, var.equal = T )\n```\n\n\nWhen should one use the t-test?\n===\nincremental:true\n- comparision of mean values against a population value or against each other\n- the t-test, especially the Welch test is appropriate whenever the underlying distributions are normal\n- it is also recommended for a group size equal or larger than 30 (robust against deviation from normality)\n\n\nExercise\n===\nincremental:true\nUse the ALLBUS data set:\n- do a test of income (V417) for the groups male and female (V81)!\n- compare the bmi (V279) of smokers and non-smokers (V272) \n- compare the bmi (V279) of people with high and normal blood pressure (V242)\n- how would you interprete the results?\n- visualize!\n\n\nSimulations with R\n===\nclass: small-code\nincremental:true\n**Rolling the dice**\n\nSuppose you are rolling a fair dice 600 times!  \n- How many sixes would you expect?\n- How many sixes do we need to reject the $H_0$-Hypotheses using a **two-sided test**?  \n- test for **EQUALITY**\n```{r}\nqbinom( p = c( .025, .975 ), size = 600, prob = 1 / 6 )\n```\n\nSimulations with R\n===\nclass: small-code\nincremental:true\nWhat do we have to change for a **one-sided test**?\n- test for **LESS**\n```{r}\nqbinom( p = .05, size = 600, prob = 1 / 6 )\n```\n\n- test for **GREATER**\n```{r}\nqbinom( p = .95, size = 600, prob = 1 / 6 )\n```\n\nSimulations with R\n===\nclass: tiny-code\nincremental:true\n\n**Now let's R roll the dice.**\n\n```{r}\n## paranthesis are for executing this row instantly\n( dice.trials <- sample( 1 : 6, 600, replace = T ) ) \n```\n\nSimulations with R\n===\nclass: tiny-code\nincremental:true\n\n**Find the sixes!**\n\n```{r}\ndice.trials == 6\n```\n\nSimulations with R\n===\nclass: tiny-code\nincremental:true\n\n**Count them!**\n\n```{r}\n## length( dice.trials[ dice.trials == 6 ] ) ## one way\nsum( dice.trials == 6 ) ## another way\n```\n\nSimulations with R\n===\nclass: tiny-code\nincremental:true\n\n**Now let's R roll the dice very very often!**\n\nNow use the following code to replicate the experiment (rolling one fair dice 600 times) 1000 times!  \nThe number of sixes are stored in the vector **dice.trials.1000**.\n\n- How many statistically significant results do you expect for a one-sided alternative? \n- How many for a two-sided alternative?\n- How many statistically significant results did you get? (You can use **table( )** in combination with a logical function.)\n- Visualize the result using **ggplot2** and **geom_histogram( )**! Look at the help of geom_histogram! Alternatively you can use **hist( )**.\n\n\nSimulations with R\n===\nclass: tiny-code\nincremental:true\n\n**Now let's R roll the dice very very often!**\n\n```{r}\ndice.trials.1000 <- replicate( 1000, sum( sample( 1 : 6, 600, replace = T ) == 6 ) )\ndf <- data.frame( repl.count = 1 : 1000, sixes.count = dice.trials.1000 )\nhead( df )\n```\n\nSimulations with R\n===\nclass: tiny-code\nincremental:true\n\n**Now let's R roll the dice very very often!**\n\n```{r}\ntable( df$sixes.count )\nquantile( df$sixes.count, probs = c( 0, .025, .05, .5, .95, .975, 1 ) )\n```\n\nSimulations with R\n===\nclass: tiny-code\nincremental:true\n\n**Now let's R roll the dice very very often!**\n\n```{r}\nhist( df$sixes.count, breaks = 50 )\n```\n\n\nSimulations with R\n===\nclass: tiny-code\nincremental:true\n\n**Now let's R roll the dice very very often!**\n\n```{r}\nlibrary( ggplot2 )\n## ??geom_histogram\nggplot( df, aes( sixes.count ) ) + geom_histogram( binwidth = 1, col = '#1A1A18', fill = '#98BD0E' ) + theme_bw( )\n```\n\n",
    "created" : 1484910827253.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2554934649",
    "id" : "47FAA9DB",
    "lastKnownWriteTime" : 1484915614,
    "last_content_update" : 1484915614404,
    "path" : "~/Development/GitHubRepos/tpeschel/R-Course/sessions/session4/slides/rpres/talk.Rpres",
    "project_path" : "talk.Rpres",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_presentation"
}